<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ActMAD</title>
  <link rel="icon" type="image/x-icon" href="static/images/car.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ActMAD: Activation Matching to Align Distributions for Test-Time-Training</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jmiemirza.github.io/" target="_blank">M. Jehanzeb Mirza</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.irs.kit.edu/People_1853.php" target="_blank">Pol Jane Soneira</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=JJRr8c8AAAAJ&hl=en" target="_blank">Wei Lin</a><sup>1</sup>,
                  </span>
              <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en" target="_blank">Mateusz Kozinski</a><sup>1</sup>,
                  </span>
              <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=iWPrl3wAAAAJ&hl=en" target="_blank">Horst Possegger</a><sup>1</sup>,
                  </span>
              <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=_pq05Q4AAAAJ&hl=en" target="_blank">Horst Bischof</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Institute for Computer Graphics and Vision, TU Graz, Austria.<br><sup>2</sup>Institute for Control Systems, KIT, Germany.
                        <br>CVPR 2023</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2211.12870.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

<!--                    &lt;!&ndash; Supplementary PDF link &ndash;&gt;-->
<!--                    <span class="link-block">-->
<!--                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"-->
<!--                      class="external-link button is-normal is-rounded is-dark">-->
<!--                      <span class="icon">-->
<!--                        <i class="fas fa-file-pdf"></i>-->
<!--                      </span>-->
<!--                      <span>Supplementary</span>-->
<!--                    </a>-->
<!--                  </span>-->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jmiemirza/ActMAD" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
<!--                <span class="link-block">-->
<!--                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"-->
<!--                  class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                    <i class="ai ai-arxiv"></i>-->
<!--                  </span>-->
<!--                  <span>Abstract</span>-->
<!--                </a>-->
<!--              </span>-->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/actmad.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Exemplary ActMAD adaptation results from KITTI-Clear &#8594; KITTI-Fog dataset.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Test-Time-Training (TTT) is an approach to cope with
out-of-distribution (OOD) data by adapting a trained model
to distribution shifts occurring at test-time. We propose to
perform this adaptation via Activation Matching (ActMAD):
We analyze activations of the model and align activation
statistics of the OOD test data to those of the training data.
In contrast to existing methods, which model the distribution
of entire channels in the ultimate layer of the feature extractor, we model the distribution of each feature in multiple
layers across the network. This results in a more fine-grained
supervision and makes ActMAD attain state of the art performance on CIFAR-100C and Imagenet-C. ActMAD is also
architecture- and task-agnostic, which lets us go beyond
image classification, and score 15.4% improvement over
previous approaches when evaluating a KITTI-trained object detector on KITTI-Fog. Our experiments highlight that
ActMAD can be applied to online adaptation in realistic
scenarios, requiring little data to attain its full performance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
                  <h2 class="title is-3">Method and Results</h2>
    <div class="level-set has-text-justified">
                <p>
                    Given a pre-trained model and statistics of the clean activations from the training data, our ActMAD aligns the
activation responses from the shifted test data to the clean activations at test-time. We model the activation distributions in terms of the means
and variances of each activation, such that the statistics have the same shape as the feature maps. The statistics of the training activations are
pre-computed on the training set, or computed on unlabelled data without distribution shift.
                </p>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/method.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Schematic of ActMAD.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/teaser.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Continuous online adaptation for ActMAD in changing weather conditions.
        </h2>
<!--      </div>-->
<!--      <div class="item">-->
<!--        &lt;!&ndash; Your image here &ndash;&gt;-->
<!--        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>-->
<!--        <h2 class="subtitle has-text-centered">-->
<!--         Third image description.-->
<!--       </h2>-->
<!--     </div>-->
<!--     <div class="item">-->
<!--      &lt;!&ndash; Your image here &ndash;&gt;-->
<!--      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        Fourth image description.-->
<!--      </h2>-->
<!--    </div>-->
  </div>
</div>
</div>
<!--</section>-->
<!-- End image carousel-->




<!--&lt;!&ndash; Youtube video &ndash;&gt;-->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--      <h2 class="title is-3">Video Presentation</h2>-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--        <div class="column is-four-fifths">-->
<!--          -->
<!--          <div class="publication-video">-->
<!--            &lt;!&ndash; Youtube embed code here &ndash;&gt;-->
<!--            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!--&lt;!&ndash; End youtube video &ndash;&gt;-->


<!--&lt;!&ndash; Video carousel &ndash;&gt;-->
<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title is-3">Another Carousel</h2>-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-video1">-->
<!--          <video poster="" id="video1" autoplay controls muted loop height="100%">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel1.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video2">-->
<!--          <video poster="" id="video2" autoplay controls muted loop height="100%">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel2.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video3">-->
<!--          <video poster="" id="video3" autoplay controls muted loop height="100%">\-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel3.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!--&lt;!&ndash; End video carousel &ndash;&gt;-->






<!-- Paper poster -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Poster</h2>-->

<!--      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">-->
<!--          </iframe>-->

<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@InProceedings{mirza2023actmad,
    author    = {Mirza, M. Jehanzeb and Soneira, Pol Jane and Lin, Wei and Kozinski, Mateusz and Possegger, Horst and Bischof, Horst},
    title     = {ActMAD: Activation Matching to Align Distributions for Test-Time Training},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2023}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            Acknowledgment for the project page: <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
<!--            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative-->
<!--            Commons Attribution-ShareAlike 4.0 International License</a>.-->
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
